{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "import glob\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    #신경망을 훈련시켜 음악을 생성하십시오.\n",
    "    notes = get_notes()\n",
    "    \n",
    "    #피치 이름을 얻습니다.\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "    \n",
    "    model = create_network(network_input, n_vocab)\n",
    "    \n",
    "    train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    #./songs 디렉토리의 midi 파일에서 모든 음과 코드를 가져옵니다.\n",
    "    notes = []\n",
    "    \n",
    "    for file in glob.glob(\"songs/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        \n",
    "        print(\"Parsing %s\" % file)\n",
    "        \n",
    "        notes_to_parse = None\n",
    "        \n",
    "        try: #파일에 악기부품이 있을 때\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "        except: #파일에 flat 형태로 있을 때\n",
    "            notes_to_parse = midi.flat.notes\n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                \n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "        \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    #신경망에서 사용하는 시퀀스를 준비\n",
    "    sequence_length = 100\n",
    "    \n",
    "    #모든 pitch 이름을 가져온다\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    \n",
    "    #pitch 를 integer 에 mapping 하는 dict 생성\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    #입력 시퀀스 & 해당 출력 생성\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "        \n",
    "    n_patterns = len(network_input)\n",
    "    \n",
    "    #입력을 LSTM 레이어와 호환되는 형식으로 재구성\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    #입력을 정규화\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    \n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    #신경망 구조 생성\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        return_sequences = True\n",
    "    ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    #신경망 훈련\n",
    "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=3, batch_size=32, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing songs/FF3_Battle_(Piano).mid\n",
      "Parsing songs/FFIX_Piano.mid\n",
      "Parsing songs/FF3_Third_Phase_Final_(Piano).mid\n",
      "Epoch 1/3\n",
      "1729/1729 [==============================] - 67s 39ms/step - loss: 4.5971\n",
      "Epoch 2/3\n",
      "1729/1729 [==============================] - 63s 36ms/step - loss: 4.2753\n",
      "Epoch 3/3\n",
      "1729/1729 [==============================] - 63s 37ms/step - loss: 4.4910\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
